{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f3/v2ckd75j2zd4t4r95xdlf_yc0000gn/T/ipykernel_18191/909766775.py:11: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  bonds_data = pd.read_csv(bonds_file_path)\n"
     ]
    }
   ],
   "source": [
    "#Clean up bond dataset \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Define paths\n",
    "master_file_path = \"/Users/kanakgarg/Desktop/Kanak/FinanceRL/data/raw_copy/raw/Master_File.csv\"\n",
    "bonds_file_path = \"/Users/kanakgarg/Desktop/Kanak/FinanceRL/data/raw_copy/raw/Bonds_Sep_2023.csv\"\n",
    "\n",
    "# Load the CSV files\n",
    "master_data = pd.read_csv(master_file_path)\n",
    "bonds_data = pd.read_csv(bonds_file_path)\n",
    "\n",
    "# Merge the datasets on the common bond identifier column\n",
    "merged_data = pd.merge(bonds_data, master_data, on='bond_sym_id')\n",
    "\n",
    "# Filter out specific columns and bonds you want to look at, and add the volume quantity\n",
    "desired_cols = [\"bond_sym_id\", \"yld_pt\", \"trd_exctn_dt\", \"mtrty_dt\", \"buy_cmsn_rt\", \"sell_cmsn_rt\", \"entrd_vol_qt\"]\n",
    "# desired_bond_sym_id = [\"AFL.GF\", \"AFL4404390\", \"AFL4972576\"]\n",
    "desired_trd_exctn_dt = [\"2023-09-01\", \"2023-09-05\",\"2023-09-06\",\"2023-09-07\",\"2023-09-08\",\"2023-09-11\", \"2023-09-12\"]\n",
    "\n",
    "# Apply those specific parameters to the filtered dataset\n",
    "filtered_data = merged_data[desired_cols]\n",
    "# filtered_data = filtered_data[filtered_data[\"bond_sym_id\"].isin(desired_bond_sym_id)]\n",
    "filtered_data = filtered_data[filtered_data[\"trd_exctn_dt\"].isin(desired_trd_exctn_dt)]\n",
    "\n",
    "if filtered_data.to_csv(\"/Users/kanakgarg/Desktop/Kanak/FinanceRL/data/raw_copy/raw/filtered_data.csv\", index=False):\n",
    "    print(\"filtered data saved in the raw_copy folder\")\n",
    "\n",
    "# Filter out rows where yld_pt is 0\n",
    "filtered_data = filtered_data[filtered_data['yld_pt'] > 0]\n",
    "\n",
    "# Group by bond symbol and trade execution date, and aggregate the data\n",
    "grouped_data = filtered_data.groupby(['trd_exctn_dt', 'bond_sym_id']).agg(\n",
    "    volume_weighted_yield=('yld_pt', lambda x: (x * filtered_data.loc[x.index, 'entrd_vol_qt']).sum() / filtered_data.loc[x.index, 'entrd_vol_qt'].sum()),\n",
    "    total_daily_volume=('entrd_vol_qt', 'sum'),\n",
    "    total_buy_commission=('buy_cmsn_rt', 'sum'),  # Sum up the buy commissions\n",
    "    total_sell_commission=('sell_cmsn_rt', 'sum'),  # Sum up the sell commissions\n",
    "    maturity_date=('mtrty_dt', 'first')  # Use the first maturity date (assuming it's the same for all rows)\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "# Ignore commissions (since they're mostly zero)\n",
    "grouped_data = grouped_data.drop(columns=['total_buy_commission', 'total_sell_commission'])\n",
    "\n",
    "# Save the grouped dataset to a CSV file\n",
    "output_path = '/Users/kanakgarg/Desktop/Kanak/FinanceRL/data/raw/all_aggregated_bond_data.csv'\n",
    "grouped_data.to_csv(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Switched the format of the dataset to be able to be viewed more easier\n",
    "#This is for the Treasury Yields \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file (adjust the sheet name if needed)\n",
    "treasury_yields_path = '/Users/kanakgarg/Desktop/Kanak/FinanceRL/data/raw/Treasury_Yields.xlsx'\n",
    "df = pd.read_excel(treasury_yields_path)\n",
    "\n",
    "#Checking to see dimensions of dataset \n",
    "# print(df.head())\n",
    "# print(\"num cols: \", len(df.columns))\n",
    "# print(\"name of cols:\", df.columns.tolist())\n",
    "\n",
    "def reshape_treasury_data(df):\n",
    "    reshaped_data = pd.DataFrame()  # Empty dataframe to store results\n",
    "    \n",
    "    # Loop through columns in pairs: (Date, Yield)\n",
    "    for i in range(0, len(df.columns), 2):\n",
    "        # Extract the pair of columns (Date column and the corresponding yield column)\n",
    "        date_col = df.columns[i]\n",
    "        yield_col = df.columns[i + 1]\n",
    "        \n",
    "        # Extract the block with the correct Date and Yield column\n",
    "        block = df[[date_col, yield_col]].copy()\n",
    "        \n",
    "        # Rename columns to 'Date' and 'Yield'\n",
    "        block.columns = ['Date', 'Yield']\n",
    "        \n",
    "        # Add a 'Maturity' column based on the yield column name\n",
    "        block['Maturity'] = yield_col\n",
    "        \n",
    "        # Concatenate the reshaped block to the final dataframe\n",
    "        reshaped_data = pd.concat([reshaped_data, block])\n",
    "\n",
    "    return reshaped_data\n",
    "\n",
    "# Reshape the data\n",
    "reshaped_data = reshape_treasury_data(df)\n",
    "\n",
    "# Ensure 'Date' is in datetime format\n",
    "reshaped_data['Date'] = pd.to_datetime(reshaped_data['Date'], errors='coerce')\n",
    "\n",
    "# Drop rows where the yield value is missing\n",
    "reshaped_data = reshaped_data.dropna(subset=['Yield'])\n",
    "\n",
    "# Save the cleaned and reshaped data to a CSV file\n",
    "reshaped_data.to_csv('/Users/kanakgarg/Desktop/Kanak/FinanceRL/data/raw/Cleaned_Treasury_Yields.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract only certain maturity time periods within the treasury dataset\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "treasury_yields_path = \"/Users/kanakgarg/Desktop/Kanak/FinanceRL/data/raw/Cleaned_Treasury_Yields.csv\"\n",
    "df = pd.read_csv(treasury_yields_path)\n",
    "\n",
    "df['Date'] = pd.to_datetime(df[\"Date\"], errors='coerce')\n",
    "\n",
    "df_2023 = df[df[\"Date\"].dt.year == 2023]\n",
    "\n",
    "df_filtered = df_2023[df_2023['Maturity'].isin(['1 Mo', '2 Mo', '6 Mo'])]\n",
    "\n",
    "filtered_csv_path = \"/Users/kanakgarg/Desktop/Kanak/FinanceRL/data/raw/Extracted_Maturity_Treasury_Yields.csv\"\n",
    "\n",
    "df_filtered.to_csv(filtered_csv_path, index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to calculate volume weighted yield for treasury bonds and add it to new dataset \n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "treasury_path = '/Users/kanakgarg/Desktop/Kanak/FinanceRL/data/raw_copy/raw/Cleaned_Treasury_Yields.csv'\n",
    "\n",
    "df = pd.read_csv(treasury_path)\n",
    "\n",
    "\n",
    "#need to look at this in more detail \n",
    "grouped_data = filtered_data.groupby(['Date']).agg(\n",
    "    volume_weighted_yield=('yld_pt', lambda x: (x * filtered_data.loc[x.index, 'entrd_vol_qt']).sum() / filtered_data.loc[x.index, 'entrd_vol_qt'].sum()),\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the two datasets into one for the model to train on \n",
    "#Will need to check on this \n",
    "import pandas as pd \n",
    "\n",
    "bonds_file_path = \"/Users/kanakgarg/Desktop/Kanak/FinanceRL/data/raw/aggregated_bond_data.csv\"\n",
    "treasury_yields_path = \"/Users/kanakgarg/Desktop/Kanak/FinanceRL/data/raw/Extracted_Maturity_Treasury_Yields.csv\"\n",
    "\n",
    "bonds_df = pd.read_csv(bonds_file_path)\n",
    "treasury_df = pd.read_csv(treasury_yields_path)\n",
    "\n",
    "bonds_df[\"trd_exctn_dt\"] = pd.to_datetime(bonds_df[\"trd_exctn_dt\"], errors=\"coerce\")\n",
    "treasury_df[\"Date\"] = pd.to_datetime(treasury_df[\"Date\"], errors=\"coerce\")\n",
    "\n",
    "merged_df = pd.merge(bonds_df, treasury_df, how= \"cross\")\n",
    "# merged_df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "merged_data_path = \"/Users/kanakgarg/Desktop/Kanak/FinanceRL/data/raw/merged_bonds_treasury_dataset.csv\"\n",
    "\n",
    "merged_df.to_csv(merged_data_path, index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
